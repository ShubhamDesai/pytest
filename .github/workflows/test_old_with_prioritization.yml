name: test
true:
  push:
    branches:
    - main
    - '[0-9]+.[0-9]+.x'
    - test-me-*
    tags:
    - '[0-9]+.[0-9]+.[0-9]+'
    - '[0-9]+.[0-9]+.[0-9]+rc[0-9]+'
  pull_request:
    branches:
    - main
    - '[0-9]+.[0-9]+.x'
    types:
    - opened
    - synchronize
    - reopened
    - ready_for_review
env:
  PYTEST_ADDOPTS: --color=yes
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true
permissions: {}
jobs:
  package:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
      with:
        fetch-depth: 0
        persist-credentials: false
    - name: Build and Check Package
      uses: hynek/build-and-inspect-python-package@v2.12.0
  build:
    needs:
    - package
    runs-on: ${{ matrix.os }}
    timeout-minutes: 45
    permissions:
      contents: read
    strategy:
      fail-fast: false
      matrix:
        name:
        - windows-py39-unittestextras
        - windows-py39-pluggy
        - windows-py39-xdist
        - windows-py310
        - windows-py311
        - windows-py312
        - windows-py313
        - ubuntu-py39-lsof-numpy-pexpect
        - ubuntu-py39-pluggy
        - ubuntu-py39-freeze
        - ubuntu-py39-xdist
        - ubuntu-py310-xdist
        - ubuntu-py311
        - ubuntu-py312
        - ubuntu-py313-pexpect
        - ubuntu-pypy3-xdist
        - macos-py39
        - macos-py310
        - macos-py312
        - macos-py313
        - doctesting
        - plugins
        include:
        - name: windows-py39-unittestextras
          python: '3.9'
          os: windows-latest
          tox_env: py39-unittestextras
          use_coverage: true
        - name: windows-py39-pluggy
          python: '3.9'
          os: windows-latest
          tox_env: py39-pluggymain-pylib-xdist
        - name: windows-py39-xdist
          python: '3.9'
          os: windows-latest
          tox_env: py39-xdist
        - name: windows-py310
          python: '3.10'
          os: windows-latest
          tox_env: py310-xdist
        - name: windows-py311
          python: '3.11'
          os: windows-latest
          tox_env: py311
        - name: windows-py312
          python: '3.12'
          os: windows-latest
          tox_env: py312
        - name: windows-py313
          python: '3.13'
          os: windows-latest
          tox_env: py313
        - name: ubuntu-py39-lsof-numpy-pexpect
          python: '3.9'
          os: ubuntu-latest
          tox_env: py39-lsof-numpy-pexpect
          use_coverage: true
        - name: ubuntu-py39-pluggy
          python: '3.9'
          os: ubuntu-latest
          tox_env: py39-pluggymain-pylib-xdist
        - name: ubuntu-py39-freeze
          python: '3.9'
          os: ubuntu-latest
          tox_env: py39-freeze
        - name: ubuntu-py39-xdist
          python: '3.9'
          os: ubuntu-latest
          tox_env: py39-xdist
        - name: ubuntu-py310-xdist
          python: '3.10'
          os: ubuntu-latest
          tox_env: py310-xdist
        - name: ubuntu-py311
          python: '3.11'
          os: ubuntu-latest
          tox_env: py311
          use_coverage: true
        - name: ubuntu-py312
          python: '3.12'
          os: ubuntu-latest
          tox_env: py312
          use_coverage: true
        - name: ubuntu-py313-pexpect
          python: '3.13'
          os: ubuntu-latest
          tox_env: py313-pexpect
          use_coverage: true
        - name: ubuntu-pypy3-xdist
          python: pypy-3.9
          os: ubuntu-latest
          tox_env: pypy3-xdist
        - name: macos-py39
          python: '3.9'
          os: macos-latest
          tox_env: py39-xdist
          use_coverage: true
        - name: macos-py310
          python: '3.10'
          os: macos-latest
          tox_env: py310-xdist
        - name: macos-py312
          python: '3.12'
          os: macos-latest
          tox_env: py312-xdist
        - name: macos-py313
          python: '3.13'
          os: macos-latest
          tox_env: py313-xdist
        - name: plugins
          python: '3.12'
          os: ubuntu-latest
          tox_env: plugins
        - name: doctesting
          python: '3.9'
          os: ubuntu-latest
          tox_env: doctesting
          use_coverage: true
    continue-on-error: "${{\n  contains(\n    fromJSON(\n      '[\n        \"windows-py39-pluggy\"\
      ,\n        \"windows-py313\",\n        \"ubuntu-py39-pluggy\",\n        \"ubuntu-py39-freeze\"\
      ,\n        \"ubuntu-py313\",\n        \"macos-py39\",\n        \"macos-py313\"\
      \n      ]'\n    ),\n    matrix.name\n  )\n  && true\n  || false\n}}"
    steps:
    - uses: actions/checkout@v4
      with:
        fetch-depth: 0
        persist-credentials: false
    - name: Download Package
      uses: actions/download-artifact@v4
      with:
        name: Packages
        path: dist
    - name: Set up Python ${{ matrix.python }}
      uses: actions/setup-python@v5
      with:
        python-version: ${{ matrix.python }}
        check-latest: ${{ endsWith(matrix.python, '-dev') }}
    - name: Install dependencies
      run: 'python -m pip install --upgrade pip

        pip install tox coverage

        '
    - name: Test without coverage
      if: '! matrix.use_coverage'
      shell: bash
      run: tox run -e ${{ matrix.tox_env }} --installpkg `find dist/*.tar.gz`
    - name: Test with coverage
      if: matrix.use_coverage
      shell: bash
      run: tox run -e ${{ matrix.tox_env }}-coverage --installpkg `find dist/*.tar.gz`
    - name: Generate coverage report
      if: matrix.use_coverage
      run: python -m coverage xml
    - name: Upload coverage to Codecov
      if: matrix.use_coverage
      uses: codecov/codecov-action@v5
      with:
        fail_ci_if_error: false
        files: ./coverage.xml
        verbose: true
  check:
    if: always()
    needs:
    - build
    runs-on: ubuntu-latest
    steps:
    - name: Decide whether the needed jobs succeeded or failed
      uses: re-actors/alls-green@223e4bb7a751b91f43eda76992bcfbf23b8b0302
      with:
        jobs: ${{ toJSON(needs) }}
  run-tests:
    runs-on: ${{ matrix.os }}
    permissions:
      contents: read
    strategy:
      fail-fast: false
      matrix:
        name:
        - windows-py39-unittestextras
        - windows-py39-pluggy
        - windows-py39-xdist
        - windows-py310
        - windows-py311
        - windows-py312
        - windows-py313
        include:
        - name: windows-py39-unittestextras
          python: '3.9'
          os: windows-latest
          tox_env: py39-unittestextras
        - name: windows-py39-pluggy
          python: '3.9'
          os: windows-latest
          tox_env: py39-pluggymain-pylib-xdist
        - name: windows-py39-xdist
          python: '3.9'
          os: windows-latest
          tox_env: py39-xdist
        - name: windows-py310
          python: '3.10'
          os: windows-latest
          tox_env: py310-xdist
        - name: windows-py311
          python: '3.11'
          os: windows-latest
          tox_env: py311
        - name: windows-py312
          python: '3.12'
          os: windows-latest
          tox_env: py312
        - name: windows-py313
          python: '3.13'
          os: windows-latest
          tox_env: py313
    steps:
    - name: Check out code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python }}
    - name: Install dependencies
      shell: bash
      run: 'python -m pip install --upgrade pip

        pip install tox pytest-json-report jq

        '
    - name: Get PR ID
      shell: bash
      if: github.event_name == 'pull_request'
      run: echo "PR_ID=${{ github.event.number }}" >> $GITHUB_ENV
    - name: Set Default Folder for Non-PR Runs
      shell: bash
      if: github.event_name != 'pull_request'
      run: echo "PR_ID=main" >> $GITHUB_ENV
    - name: Check If Previous Artifacts Exist
      id: check_artifacts
      shell: bash
      run: "echo \"Checking if previous test results exist for PR-${PR_ID}...\"\n\
        ARTIFACTS_RESPONSE=$(curl -s -H \"Authorization: token ${{ secrets.GITHUB_TOKEN\
        \ }}\" \\\n  -H \"Accept: application/vnd.github.v3+json\" \\\n  \"https://api.github.com/repos/${{\
        \ github.repository }}/actions/artifacts\")\n\nARTIFACT_COUNT=$(echo \"$ARTIFACTS_RESPONSE\"\
        \ | jq -r --arg PR \"pr-${PR_ID}-test-results\" \\\n  '[.artifacts[] | select(.name==$PR)]\
        \ | length')\n\nif [[ \"$ARTIFACT_COUNT\" -gt 0 ]]; then\n  echo \"PREV_ARTIFACT_EXISTS=true\"\
        \ >> $GITHUB_ENV\nelse\n  echo \"PREV_ARTIFACT_EXISTS=false\" >> $GITHUB_ENV\n\
        fi\n"
    - name: Retrieve Previous Artifacts (If Exists)
      if: env.PREV_ARTIFACT_EXISTS == 'true'
      shell: bash
      run: "echo \"Fetching previous test results for PR ${PR_ID}...\"\n\nARTIFACT_URL=$(curl\
        \ -s -H \"Authorization: token ${{ secrets.GITHUB_TOKEN }}\" \\\n  -H \"Accept:\
        \ application/vnd.github.v3+json\" \\\n  \"https://api.github.com/repos/${{\
        \ github.repository }}/actions/artifacts\" | \\\n  jq -r --arg PR \"pr-${PR_ID}-test-results\"\
        \ \\\n  '[.artifacts[] | select(.name==$PR)] | sort_by(.created_at) | reverse\
        \ | .[0].archive_download_url')\n\nif [[ -n \"$ARTIFACT_URL\" && \"$ARTIFACT_URL\"\
        \ != \"null\" ]]; then\n  echo \"Latest artifact found. Downloading...\"\n\
        \  mkdir -p artifacts/pr-${PR_ID}\n  curl -L -H \"Authorization: token ${{\
        \ secrets.GITHUB_TOKEN }}\" \\\n       -o artifacts/pr-${PR_ID}/test-results.zip\
        \ \"$ARTIFACT_URL\"\n  unzip -o artifacts/pr-${PR_ID}/test-results.zip -d\
        \ artifacts/pr-${PR_ID}\n\n  echo \"=======================================\"\
        \n  echo \"Previous Test Results for PR-${PR_ID}:\"\n  cat artifacts/pr-${PR_ID}/test_results.json\
        \ || echo \"No previous test results found.\"\n  echo \"=======================================\"\
        \nelse\n  echo \"No previous test results found for PR-${PR_ID}. Running fresh\
        \ tests.\"\nfi\n"
    - name: Extract Failed and Passed Tests from Previous Run
      shell: bash
      run: "mkdir -p artifacts/pr-${PR_ID}\nPREV_RESULTS=\"artifacts/pr-${PR_ID}/test_results.json\"\
        \nFAILED_TESTS_FILE=\"artifacts/pr-${PR_ID}/failed_tests.txt\"\nALL_TESTS_FILE=\"\
        artifacts/pr-${PR_ID}/all_tests.txt\"\nREMAINING_TESTS_FILE=\"artifacts/pr-${PR_ID}/remaining_tests.txt\"\
        \n\n  # Use tox to collect all tests\ntox -e ${{ matrix.tox_env }} -- --collect-only\
        \ --quiet | grep -v \"SKIP\" | grep \"::\" > $ALL_TESTS_FILE || true\n#tox\
        \ -e ${{ matrix.tox_env }} -- --collect-only -v | grep -v \"SKIP\" | grep\
        \ -E \"^(.*?)::\" | sed -E 's/\\s+.*$//' > $ALL_TESTS_FILE || true\n\nif [[\
        \ -f \"$PREV_RESULTS\" ]]; then\n  echo \"Extracting failed test cases from\
        \ previous run...\"\n  cat $PREV_RESULTS | jq -r '.tests | map(select(.outcome\
        \ == \"failed\")) | .[].nodeid' > $FAILED_TESTS_FILE\nelse\n  echo \"No previous\
        \ test results found. Skipping extraction.\"\n  touch $FAILED_TESTS_FILE\n\
        fi\n\nif [[ -s \"$FAILED_TESTS_FILE\" ]]; then\n  echo \"Failed tests from\
        \ the previous run:\"\n  cat $FAILED_TESTS_FILE\nelse\n  echo \"No previously\
        \ failed tests found.\"\nfi\n"
    - name: Pre-Check for Previously Failed Tests
      shell: bash
      run: "FAILED_TESTS_FILE=\"artifacts/pr-${PR_ID}/failed_tests.txt\"\nSKIPPED_TESTS_FILE=\"\
        artifacts/pr-${PR_ID}/skipped_tests.txt\"\n\n# Only run this check if we have\
        \ previously failed tests\nif [[ -s \"$FAILED_TESTS_FILE\" ]]; then\n  echo\
        \ \"Checking for skipped tests among previously failed tests...\"\n  tox -e\
        \ ${{ matrix.tox_env }} -- --collect-only -v $(cat $FAILED_TESTS_FILE) | grep\
        \ \"SKIP\" | grep \"::\" | sed 's/.*SKIP //g' > $SKIPPED_TESTS_FILE\n\n  #\
        \ Remove skipped tests from the failed tests list\n  if [[ -s \"$SKIPPED_TESTS_FILE\"\
        \ ]]; then\n    echo \"Removing skipped tests from the rerun list:\"\n   \
        \ cat $SKIPPED_TESTS_FILE\n    grep -v -F -f $SKIPPED_TESTS_FILE $FAILED_TESTS_FILE\
        \ > \"artifacts/pr-${PR_ID}/filtered_failed_tests.txt\"\n    mv \"artifacts/pr-${PR_ID}/filtered_failed_tests.txt\"\
        \ $FAILED_TESTS_FILE\n  else\n    echo \"No skipped tests found among previously\
        \ failed tests.\"\n  fi\nfi\n"
    - name: Generate Failed Test Commands
      shell: bash
      run: "FAILED_TESTS_FILE=\"artifacts/pr-${PR_ID}/failed_tests.txt\"\n\nif [[\
        \ -s \"$FAILED_TESTS_FILE\" ]]; then\n  python scripts/generate_pytest_commands.py\
        \ --input artifacts/pr-${PR_ID}/remaining_tests.txt --output-dir artifacts\
        \ --pr-id ${PR_ID} --generate-script --batch-size 50 --tox-env ${{ matrix.tox_env\
        \ }}\nfi\n  \n"
    - name: Run Previously Failed Tests First
      shell: bash
      run: "FAILED_TESTS_FILE=\"artifacts/pr-${PR_ID}/failed_tests.txt\"\n\nif [[\
        \ -s \"$FAILED_TESTS_FILE\" ]]; then\n  echo \"Rerunning previously failed\
        \ tests using tox env ${{ matrix.tox_env }}...\"\n  \n  if [[ -f \"artifacts/pr-${PR_ID}/run_failed_tests.sh\"\
        \ ]]; then\n    chmod +x artifacts/pr-${PR_ID}/run_failed_tests.sh\n    bash\
        \ artifacts/pr-${PR_ID}/run_failed_tests.sh\n  else\n    echo \"No failed\
        \ test script generated.\"\n  fi\nelse\n  echo \"No previously failed tests\
        \ found.\"\nfi\n"
    - name: Check If Any Tests Failed Again
      shell: bash
      run: "TEMP_RESULTS=\"artifacts/pr-${PR_ID}/temp_test_results.json\"\nFAILED_AGAIN_FILE=\"\
        artifacts/pr-${PR_ID}/failed_again.txt\"\n\nif [[ -f \"$TEMP_RESULTS\" ]];\
        \ then\n  echo \"Analyzing test results...\"\n  # Extract failed tests (excluding\
        \ skipped)\n  cat $TEMP_RESULTS | jq -r '.tests | map(select(.outcome == \"\
        failed\")) | .[].nodeid' > $FAILED_AGAIN_FILE\n  # Extract skipped tests for\
        \ reporting\n  cat $TEMP_RESULTS | jq -r '.tests | map(select(.outcome ==\
        \ \"skipped\")) | .[].nodeid' > \"artifacts/pr-${PR_ID}/skipped_tests_report.txt\"\
        \n  \n  # Report on skipped tests\n  if [[ -s \"artifacts/pr-${PR_ID}/skipped_tests_report.txt\"\
        \ ]]; then\n    echo \"The following tests were skipped during execution:\"\
        \n    cat \"artifacts/pr-${PR_ID}/skipped_tests_report.txt\"\n  fi\nfi\n\n\
        if [[ -s \"$FAILED_AGAIN_FILE\" ]]; then\n  echo \"Some tests failed again.\
        \ Stopping execution.\"\n  exit 1\nfi\n"
    - name: Identify Remaining Untested Test Cases
      shell: bash
      run: "FAILED_TESTS_FILE=\"artifacts/pr-${PR_ID}/failed_tests.txt\"\nALL_TESTS_FILE=\"\
        artifacts/pr-${PR_ID}/all_tests.txt\"\nREMAINING_TESTS_FILE=\"artifacts/pr-${PR_ID}/remaining_tests.txt\"\
        \n\necho \"Finding remaining tests to run...\"\ngrep -v -F -f $FAILED_TESTS_FILE\
        \ $ALL_TESTS_FILE > $REMAINING_TESTS_FILE || true\n\nif [[ -s \"$REMAINING_TESTS_FILE\"\
        \ ]]; then\n  echo \"Remaining tests to run:\"\n  cat $REMAINING_TESTS_FILE\n\
        else\n  echo \"No remaining tests to run.\"\nfi\n"
    - name: Set Workflow ID
      shell: bash
      run: echo "WORKFLOW_ID=${{ matrix.name }}" >> $GITHUB_ENV
    - name: Generate Test Commands
      shell: bash
      run: 'python scripts/generate_pytest_commands.py --input artifacts/pr-${PR_ID}/remaining_tests.txt
        --output-dir artifacts --pr-id ${PR_ID} --workflow-id ${WORKFLOW_ID} --generate-script
        --batch-size 20 --tox-env ${{ matrix.tox_env }}

        '
    - name: Display Retrieved Test Results
      shell: bash
      run: "RUN_TESTS_FILE=\"artifacts/pr-${PR_ID}/run_tests.sh\"\nif [[ -f \"$RUN_TESTS_FILE\"\
        \ ]]; then\n  echo \"Content of run_tests.sh:\"\n  cat \"$RUN_TESTS_FILE\"\
        \nelse\n  echo \"run_tests.sh file does not exist.\"\nfi\n"
    - name: Run Remaining Test Cases
      shell: bash
      run: "REMAINING_TESTS_FILE=\"artifacts/pr-${PR_ID}/remaining_tests.txt\"\n\n\
        if [[ -s \"$REMAINING_TESTS_FILE\" ]]; then\n  echo \"Running remaining test\
        \ cases using tox env ${{ matrix.tox_env }}...\"\n  \n  if [[ -f \"artifacts/pr-${PR_ID}/${WORKFLOW_ID}/run_tests.sh\"\
        \ ]]; then\n    chmod +x artifacts/pr-${PR_ID}/${WORKFLOW_ID}/run_tests.sh\n\
        \    bash artifacts/pr-${PR_ID}/${WORKFLOW_ID}/run_tests.sh\n    \n    # Combine\
        \ results after running tests\n    python scripts/generate_pytest_commands.py\
        \ --combine-results --output-dir=artifacts --pr-id=${PR_ID} --workflow-id=${WORKFLOW_ID}\n\
        \  else\n    echo \"No test script generated.\"\n  fi\nelse\n  echo \"No remaining\
        \ tests to run.\"\nfi\n    \n"
    - name: Upload New Test Results
      uses: actions/upload-artifact@v4
      with:
        name: pr-${{ env.PR_ID }}-${{ env.WORKFLOW_ID }}-test-results
        path: "artifacts/pr-${{ env.PR_ID }}/${{ env.WORKFLOW_ID }}/test_results.json\n\
          artifacts/pr-${{ env.PR_ID }}/${{ env.WORKFLOW_ID }}/*.sh\n    \n"
  retrieve-results:
    needs: run-tests
    runs-on: ubuntu-latest
    steps:
    - name: Get PR ID
      if: github.event_name == 'pull_request'
      run: echo "PR_ID=${{ github.event.number }}" >> $GITHUB_ENV
    - name: Set Default Folder for Non-PR Runs
      if: github.event_name != 'pull_request'
      run: echo "PR_ID=main" >> $GITHUB_ENV
    - name: Check out code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
    - name: Install dependencies
      shell: bash
      run: 'python -m pip install --upgrade pip

        pip install jq

        '
    - name: Create directory for results
      run: mkdir -p retrieved-results
    - name: Download all workflow test results
      uses: actions/download-artifact@v4
      with:
        pattern: pr-${{ env.PR_ID }}-*-test-results
        path: retrieved-results
        merge-multiple: false
    - name: Debug directory structure
      shell: bash
      run: 'echo "Debugging directory structure..."

        find retrieved-results -type f | sort

        '
    - name: Extract zip files if needed
      shell: bash
      run: "echo \"Extracting downloaded artifacts...\"\nfor zip_file in $(find retrieved-results\
        \ -name \"*.zip\"); do\n  if [ -f \"$zip_file\" ]; then\n    workflow_dir=$(dirname\
        \ \"$zip_file\")\n    echo \"Extracting $zip_file to $workflow_dir\"\n   \
        \ unzip -o \"$zip_file\" -d \"$workflow_dir\"\n  fi\ndone\n"
    - name: Find test result files
      shell: bash
      run: 'echo "======================================="

        echo "Downloaded artifacts for PR ${PR_ID}:"

        find retrieved-results -type f -name "test_results*.json" | sort

        echo "======================================="

        '
    - name: Combine test results
      shell: bash
      run: "echo \"Combining test results from all workflows...\"\n\n# Initialize\
        \ combined results file\ncat > retrieved-results/combined_results.json <<\
        \ EOF\n{\n  \"created\": \"$(date -Iseconds)\",\n  \"duration\": 0,\n  \"\
        exitcode\": 0,\n  \"summary\": {\n    \"passed\": 0,\n    \"failed\": 0,\n\
        \    \"skipped\": 0,\n    \"xfailed\": 0,\n    \"xpassed\": 0,\n    \"error\"\
        : 0,\n    \"total\": 0\n  },\n  \"tests\": [],\n  \"collectors\": [],\n  \"\
        warnings\": []\n}\nEOF\n\n# Find all test_results.json files\nfor result_file\
        \ in $(find retrieved-results -type f -name \"test_results*.json\"); do\n\
        \  echo \"Processing $result_file\"\n  \n  # Check if file is valid JSON\n\
        \  if ! jq empty \"$result_file\" 2>/dev/null; then\n    echo \"Warning: $result_file\
        \ is not valid JSON, skipping\"\n    continue\n  fi\n  \n  # Update summary\
        \ counts\n  for metric in passed failed skipped xfailed xpassed error total;\
        \ do\n    count=$(jq -r \".summary.$metric // 0\" \"$result_file\")\n    current=$(jq\
        \ -r \".summary.$metric\" retrieved-results/combined_results.json)\n    new_count=$((current\
        \ + count))\n    jq --arg metric \"$metric\" --argjson count \"$new_count\"\
        \ '.summary[$metric] = $count' retrieved-results/combined_results.json > temp.json\
        \ && mv temp.json retrieved-results/combined_results.json\n  done\n  \n  #\
        \ Add tests\n  jq -s '.[0].tests = (.[0].tests + (.[1].tests // [])); .[0]'\
        \ retrieved-results/combined_results.json \"$result_file\" > temp.json &&\
        \ mv temp.json retrieved-results/combined_results.json\n  \n  # Add duration\n\
        \  duration=$(jq -r \".duration // 0\" \"$result_file\")\n  current_duration=$(jq\
        \ -r \".duration\" retrieved-results/combined_results.json)\n  new_duration=$(echo\
        \ \"$current_duration + $duration\" | bc)\n  jq --argjson duration \"$new_duration\"\
        \ '.duration = $duration' retrieved-results/combined_results.json > temp.json\
        \ && mv temp.json retrieved-results/combined_results.json\n  \n  # Update\
        \ exitcode (non-zero takes precedence)\n  exitcode=$(jq -r \".exitcode //\
        \ 0\" \"$result_file\")\n  current_exitcode=$(jq -r \".exitcode\" retrieved-results/combined_results.json)\n\
        \  if [ \"$exitcode\" -ne 0 ] && [ \"$current_exitcode\" -eq 0 ]; then\n \
        \   jq --argjson exitcode \"$exitcode\" '.exitcode = $exitcode' retrieved-results/combined_results.json\
        \ > temp.json && mv temp.json retrieved-results/combined_results.json\n  fi\n\
        done\n\n# Create a copy as test_results.json for backward compatibility\n\
        cp retrieved-results/combined_results.json retrieved-results/test_results.json\n"
    - name: Display Combined Test Results
      shell: bash
      run: 'echo "======================================="

        echo "Combined Test Results from PR ${PR_ID}:"

        echo "Summary:"

        jq ''.summary'' retrieved-results/combined_results.json

        echo "Failed Tests:"

        jq -r ''.tests | map(select(.outcome == "failed")) | .[].nodeid'' retrieved-results/combined_results.json
        || echo "No failed tests found."

        echo "======================================="

        '
    - name: Upload Combined Results
      uses: actions/upload-artifact@v4
      with:
        name: pr-${{ env.PR_ID }}-combined-test-results
        path: retrieved-results/combined_results.json
