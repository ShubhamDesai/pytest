name: test

on:
  push:
    branches:
      - main
      - "[0-9]+.[0-9]+.x"
      - "test-me-*"
    tags:
      - "[0-9]+.[0-9]+.[0-9]+"
      - "[0-9]+.[0-9]+.[0-9]+rc[0-9]+"

  pull_request:
    branches:
      - main
      - "[0-9]+.[0-9]+.x"
    types: [opened, synchronize, reopened, ready_for_review]

env:
  PYTEST_ADDOPTS: "--color=yes"

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

permissions:
  actions: read

jobs:
  run-tests:
    runs-on: ${{ matrix.os }}
    permissions:
      contents: read

    strategy:
      fail-fast: false
      matrix:
        name: [
          "windows-py39-unittestextras",
          "windows-py39-pluggy",
          "windows-py39-xdist",
          "windows-py310",
          "windows-py311",
          "windows-py312",
          "windows-py313"
        ]

        include:
          - name: "windows-py39-unittestextras"
            python: "3.9"
            os: windows-latest
            tox_env: "py39-unittestextras"

          - name: "windows-py39-pluggy"
            python: "3.9"
            os: windows-latest
            tox_env: "py39-pluggymain-pylib-xdist"

          - name: "windows-py39-xdist"
            python: "3.9"
            os: windows-latest
            tox_env: "py39-xdist"

          - name: "windows-py310"
            python: "3.10"
            os: windows-latest
            tox_env: "py310-xdist"

          - name: "windows-py311"
            python: "3.11"
            os: windows-latest
            tox_env: "py311"

          - name: "windows-py312"
            python: "3.12"
            os: windows-latest
            tox_env: "py312"

          - name: "windows-py313"
            python: "3.13"
            os: windows-latest
            tox_env: "py313"

    steps:
      - name: Check out code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python }}

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install tox pytest-json-report jq

      - name: Get PR ID
        if: github.event_name == 'pull_request'
        run: echo "PR_ID=${{ github.event.number }}" >> $GITHUB_ENV

      - name: Set Default Folder for Non-PR Runs
        if: github.event_name != 'pull_request'
        run: echo "PR_ID=main" >> $GITHUB_ENV

      - name: Check if Artifact Exists for Workflow
        run: |
          ARTIFACTS_RESPONSE=$(curl -s -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" \
            -H "Accept: application/vnd.github.v3+json" \
            "https://api.github.com/repos/${{ github.repository }}/actions/artifacts")

          ARTIFACT_COUNT=$(echo "$ARTIFACTS_RESPONSE" | jq -r --arg ART "pr-${{ env.PR_ID }}-${{ matrix.name }}-test-results" '[.artifacts[] | select(.name==$ART)] | length')

          if [[ "$ARTIFACT_COUNT" -gt 0 ]]; then
            echo "PREV_ARTIFACT_EXISTS=true" >> $GITHUB_ENV
          else
            echo "PREV_ARTIFACT_EXISTS=false" >> $GITHUB_ENV
          fi

      - name: Run full test suite if no artifact exists
        if: env.PREV_ARTIFACT_EXISTS != 'true'
        run: |
          mkdir -p artifacts/pr-${{ env.PR_ID }}/${{ matrix.name }}
          tox -e ${{ matrix.tox_env }} -- --json-report --json-report-file=artifacts/pr-${{ env.PR_ID }}/${{ matrix.name }}/test_results.json

      - name: Download and extract previous artifact if exists
        if: env.PREV_ARTIFACT_EXISTS == 'true'
        run: |
          ARTIFACT_URL=$(curl -s -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" \
            -H "Accept: application/vnd.github.v3+json" \
            "https://api.github.com/repos/${{ github.repository }}/actions/artifacts" | \
            jq -r --arg ART "pr-${{ env.PR_ID }}-${{ matrix.name }}-test-results" '[.artifacts[] | select(.name==$ART)] | sort_by(.created_at) | reverse | .[0].archive_download_url')

          if [[ -n "$ARTIFACT_URL" && "$ARTIFACT_URL" != "null" ]]; then
            mkdir -p artifacts/pr-${{ env.PR_ID }}/${{ matrix.name }}
            curl -L -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" \
              -o artifacts/pr-${{ env.PR_ID }}/${{ matrix.name }}/test-results.zip "$ARTIFACT_URL"
            unzip -o artifacts/pr-${{ env.PR_ID }}/${{ matrix.name }}/test-results.zip -d artifacts/pr-${{ env.PR_ID }}/${{ matrix.name }}
          fi

      - name: Collect all test cases and split failed vs remaining
        run: |
          PREV_RESULTS=artifacts/pr-${{ env.PR_ID }}/${{ matrix.name }}/test_results.json
          FAILED=artifacts/pr-${{ env.PR_ID }}/${{ matrix.name }}/failed_tests.txt
          ALL=artifacts/pr-${{ env.PR_ID }}/${{ matrix.name }}/all_tests.txt
          REMAIN=artifacts/pr-${{ env.PR_ID }}/${{ matrix.name }}/remaining_tests.txt

          tox -e ${{ matrix.tox_env }} -- --collect-only --quiet | grep '::' > "$ALL" || true

          if [[ -f "$PREV_RESULTS" ]]; then
            jq -r '.tests | map(select(.outcome == "failed")) | .[].nodeid' "$PREV_RESULTS" > "$FAILED"
            grep -v -F -f "$FAILED" "$ALL" > "$REMAIN" || true
          else
            cp "$ALL" "$REMAIN"
          fi

      - name: Run failed tests (if any)
        run: |
          FAILED_FILE=artifacts/pr-${{ env.PR_ID }}/${{ matrix.name }}/failed_tests.txt
          if [[ -s "$FAILED_FILE" ]]; then
            python scripts/generate_pytest_commands.py \
              --input "$FAILED_FILE" \
              --output-dir artifacts/pr-${{ env.PR_ID }}/${{ matrix.name }} \
              --pr-id ${{ env.PR_ID }} --workflow-id ${{ matrix.name }} \
              --generate-script --batch-size 50 --tox-env ${{ matrix.tox_env }}

            chmod +x artifacts/pr-${{ env.PR_ID }}/${{ matrix.name }}/run_failed_tests.sh
            bash artifacts/pr-${{ env.PR_ID }}/${{ matrix.name }}/run_failed_tests.sh || exit 1
          fi

      - name: Run remaining tests (if needed)
        run: |
          REMAIN_FILE=artifacts/pr-${{ env.PR_ID }}/${{ matrix.name }}/remaining_tests.txt
          if [[ -s "$REMAIN_FILE" ]]; then
            python scripts/generate_pytest_commands.py \
              --input "$REMAIN_FILE" \
              --output-dir artifacts/pr-${{ env.PR_ID }}/${{ matrix.name }} \
              --pr-id ${{ env.PR_ID }} --workflow-id ${{ matrix.name }} \
              --generate-script --batch-size 20 --tox-env ${{ matrix.tox_env }}

            chmod +x artifacts/pr-${{ env.PR_ID }}/${{ matrix.name }}/run_tests.sh
            bash artifacts/pr-${{ env.PR_ID }}/${{ matrix.name }}/run_tests.sh
          fi

      - name: Upload per-workflow test results
        uses: actions/upload-artifact@v4
        with:
          name: pr-${{ env.PR_ID }}-${{ matrix.name }}-test-results
          path: |
            artifacts/pr-${{ env.PR_ID }}/${{ matrix.name }}/test_results.json
            artifacts/pr-${{ env.PR_ID }}/${{ matrix.name }}/*.sh

  retrieve-results:
    needs: run-tests
    runs-on: ubuntu-latest
    steps:
      - name: Get PR ID
        run: echo "PR_ID=${{ github.event.number || 'main' }}" >> $GITHUB_ENV

      - name: Check out code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.9"

      - name: Install dependencies
        run: pip install jq

      - name: Download all workflow results
        uses: actions/download-artifact@v4
        with:
          pattern: pr-${{ env.PR_ID }}-*-test-results
          path: retrieved-results
          merge-multiple: false

      - name: Display per-workflow summaries
        run: |
          echo "================ Per-Workflow Results ================"
          for result_file in $(find retrieved-results -name test_results.json); do
            echo "--- Summary for ${result_file} ---"
            jq '.summary' "$result_file" || echo "No summary found"
            echo "Failed Tests:"
            jq -r '.tests | map(select(.outcome == "failed")) | .[].nodeid' "$result_file" || echo "No failed tests"
            echo "====================================================="
          done

      - name: Upload Combined Results
        uses: actions/upload-artifact@v4
        with:
          name: pr-${{ env.PR_ID }}-combined-test-results
          path: retrieved-results
