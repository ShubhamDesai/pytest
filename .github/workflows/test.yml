name: test

on:
  push:
    branches:
      - main
      - "[0-9]+.[0-9]+.x"
      - "test-me-*"
    tags:
      - "[0-9]+.[0-9]+.[0-9]+"
      - "[0-9]+.[0-9]+.[0-9]+rc[0-9]+"

  pull_request:
    branches:
      - main
      - "[0-9]+.[0-9]+.x"
    types: [opened, synchronize, reopened, ready_for_review]

env:
  PYTEST_ADDOPTS: "--color=yes"
  # SETUPTOOLS_SCM_PRETEND_VERSION: "7.3.1.dev0"
  # SETUPTOOLS_SCM_NO_LOCAL_VERSION: "1"

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

permissions:
  actions: read

jobs:
  run-tests:
    runs-on: ${{ matrix.os }}
    permissions:
      contents: read

    strategy:
      fail-fast: false
      matrix:
        name: [
          "windows-py39-unittestextras",
          "windows-py39-pluggy",
          "windows-py39-xdist",
          "windows-py310",
          "windows-py311",
          "windows-py312",
          "windows-py313"
        ]

        include:
          - name: "windows-py39-unittestextras"
            python: "3.9"
            os: windows-latest
            tox_env: "py39-unittestextras"

          - name: "windows-py39-pluggy"
            python: "3.9"
            os: windows-latest
            tox_env: "py39-pluggymain-pylib-xdist"

          - name: "windows-py39-xdist"
            python: "3.9"
            os: windows-latest
            tox_env: "py39-xdist"

          - name: "windows-py310"
            python: "3.10"
            os: windows-latest
            tox_env: "py310-xdist"

          - name: "windows-py311"
            python: "3.11"
            os: windows-latest
            tox_env: "py311"

          - name: "windows-py312"
            python: "3.12"
            os: windows-latest
            tox_env: "py312"

          - name: "windows-py313"
            python: "3.13"
            os: windows-latest
            tox_env: "py313"

    steps:
      - name: Check out code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python }}

      - name: Install dependencies
        shell: bash
        run: |
          python -m pip install --upgrade pip
          pip install tox pytest-json-report jq

      - name: Get PR ID
        shell: bash
        if: github.event_name == 'pull_request'
        run: echo "PR_ID=${{ github.event.number }}" >> $GITHUB_ENV

      - name: Set Default Folder for Non-PR Runs
        shell: bash
        if: github.event_name != 'pull_request'
        run: echo "PR_ID=main" >> $GITHUB_ENV

      - name: Check If Previous Artifacts Exist
        id: check_artifacts
        shell: bash
        run: |
          echo "Checking if previous test results exist for PR-${PR_ID}..."
          ARTIFACTS_RESPONSE=$(curl -s -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" \
            -H "Accept: application/vnd.github.v3+json" \
            "https://api.github.com/repos/${{ github.repository }}/actions/artifacts")

          ARTIFACT_COUNT=$(echo "$ARTIFACTS_RESPONSE" | jq -r --arg PR "pr-${PR_ID}-test-results" \
            '[.artifacts[] | select(.name==$PR)] | length')

          if [[ "$ARTIFACT_COUNT" -gt 0 ]]; then
            echo "PREV_ARTIFACT_EXISTS=true" >> $GITHUB_ENV
          else
            echo "PREV_ARTIFACT_EXISTS=false" >> $GITHUB_ENV
          fi

      - name: Retrieve Previous Artifacts (If Exists)
        if: env.PREV_ARTIFACT_EXISTS == 'true'
        shell: bash
        run: |
          echo "Fetching previous test results for PR ${PR_ID}..."

          ARTIFACT_URL=$(curl -s -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" \
            -H "Accept: application/vnd.github.v3+json" \
            "https://api.github.com/repos/${{ github.repository }}/actions/artifacts" | \
            jq -r --arg PR "pr-${PR_ID}-test-results" \
            '[.artifacts[] | select(.name==$PR)] | sort_by(.created_at) | reverse | .[0].archive_download_url')

          if [[ -n "$ARTIFACT_URL" && "$ARTIFACT_URL" != "null" ]]; then
            echo "Latest artifact found. Downloading..."
            mkdir -p artifacts/pr-${PR_ID}
            curl -L -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" \
                 -o artifacts/pr-${PR_ID}/test-results.zip "$ARTIFACT_URL"
            unzip -o artifacts/pr-${PR_ID}/test-results.zip -d artifacts/pr-${PR_ID}

            echo "======================================="
            echo "Previous Test Results for PR-${PR_ID}:"
            cat artifacts/pr-${PR_ID}/test_results.json || echo "No previous test results found."
            echo "======================================="
          else
            echo "No previous test results found for PR-${PR_ID}. Running fresh tests."
          fi

      - name: Extract Failed and Passed Tests from Previous Run
        shell: bash
        run: |
          mkdir -p artifacts/pr-${PR_ID}
          PREV_RESULTS="artifacts/pr-${PR_ID}/test_results.json"
          FAILED_TESTS_FILE="artifacts/pr-${PR_ID}/failed_tests.txt"
          ALL_TESTS_FILE="artifacts/pr-${PR_ID}/all_tests.txt"
          REMAINING_TESTS_FILE="artifacts/pr-${PR_ID}/remaining_tests.txt"
        
            # Use tox to collect all tests
          tox -e ${{ matrix.tox_env }} -- --collect-only --quiet | grep -v "SKIP" | grep "::" > $ALL_TESTS_FILE || true
          #tox -e ${{ matrix.tox_env }} -- --collect-only -v | grep -v "SKIP" | grep -E "^(.*?)::" | sed -E 's/\s+.*$//' > $ALL_TESTS_FILE || true

          if [[ -f "$PREV_RESULTS" ]]; then
            echo "Extracting failed test cases from previous run..."
            cat $PREV_RESULTS | jq -r '.tests | map(select(.outcome == "failed")) | .[].nodeid' > $FAILED_TESTS_FILE
          else
            echo "No previous test results found. Skipping extraction."
            touch $FAILED_TESTS_FILE
          fi
        
          if [[ -s "$FAILED_TESTS_FILE" ]]; then
            echo "Failed tests from the previous run:"
            cat $FAILED_TESTS_FILE
          else
            echo "No previously failed tests found."
          fi
     
      - name: Pre-Check for Previously Failed Tests
        shell: bash
        run: |
          FAILED_TESTS_FILE="artifacts/pr-${PR_ID}/failed_tests.txt"
          SKIPPED_TESTS_FILE="artifacts/pr-${PR_ID}/skipped_tests.txt"
      
          # Only run this check if we have previously failed tests
          if [[ -s "$FAILED_TESTS_FILE" ]]; then
            echo "Checking for skipped tests among previously failed tests..."
            tox -e ${{ matrix.tox_env }} -- --collect-only -v $(cat $FAILED_TESTS_FILE) | grep "SKIP" | grep "::" | sed 's/.*SKIP //g' > $SKIPPED_TESTS_FILE

            # Remove skipped tests from the failed tests list
            if [[ -s "$SKIPPED_TESTS_FILE" ]]; then
              echo "Removing skipped tests from the rerun list:"
              cat $SKIPPED_TESTS_FILE
              grep -v -F -f $SKIPPED_TESTS_FILE $FAILED_TESTS_FILE > "artifacts/pr-${PR_ID}/filtered_failed_tests.txt"
              mv "artifacts/pr-${PR_ID}/filtered_failed_tests.txt" $FAILED_TESTS_FILE
            else
              echo "No skipped tests found among previously failed tests."
            fi
          fi

      - name: Generate Failed Test Commands
        shell: bash
        run: |
          FAILED_TESTS_FILE="artifacts/pr-${PR_ID}/failed_tests.txt"
          
          if [[ -s "$FAILED_TESTS_FILE" ]]; then
            python scripts/generate_pytest_commands.py --input artifacts/pr-${PR_ID}/remaining_tests.txt --output-dir artifacts --pr-id ${PR_ID} --generate-script --batch-size 50 --tox-env ${{ matrix.tox_env }}
          fi
            
      - name: Run Previously Failed Tests First
        shell: bash
        run: |
          FAILED_TESTS_FILE="artifacts/pr-${PR_ID}/failed_tests.txt"
      
          if [[ -s "$FAILED_TESTS_FILE" ]]; then
            echo "Rerunning previously failed tests using tox env ${{ matrix.tox_env }}..."
            
            if [[ -f "artifacts/pr-${PR_ID}/run_failed_tests.sh" ]]; then
              chmod +x artifacts/pr-${PR_ID}/run_failed_tests.sh
              bash artifacts/pr-${PR_ID}/run_failed_tests.sh
            else
              echo "No failed test script generated."
            fi
          else
            echo "No previously failed tests found."
          fi
        

      - name: Check If Any Tests Failed Again
        shell: bash
        run: |
          TEMP_RESULTS="artifacts/pr-${PR_ID}/temp_test_results.json"
          FAILED_AGAIN_FILE="artifacts/pr-${PR_ID}/failed_again.txt"
          
          if [[ -f "$TEMP_RESULTS" ]]; then
            echo "Analyzing test results..."
            # Extract failed tests (excluding skipped)
            cat $TEMP_RESULTS | jq -r '.tests | map(select(.outcome == "failed")) | .[].nodeid' > $FAILED_AGAIN_FILE
            # Extract skipped tests for reporting
            cat $TEMP_RESULTS | jq -r '.tests | map(select(.outcome == "skipped")) | .[].nodeid' > "artifacts/pr-${PR_ID}/skipped_tests_report.txt"
            
            # Report on skipped tests
            if [[ -s "artifacts/pr-${PR_ID}/skipped_tests_report.txt" ]]; then
              echo "The following tests were skipped during execution:"
              cat "artifacts/pr-${PR_ID}/skipped_tests_report.txt"
            fi
          fi
          
          if [[ -s "$FAILED_AGAIN_FILE" ]]; then
            echo "Some tests failed again. Stopping execution."
            exit 1
          fi

      - name: Identify Remaining Untested Test Cases
        shell: bash
        run: |
          FAILED_TESTS_FILE="artifacts/pr-${PR_ID}/failed_tests.txt"
          ALL_TESTS_FILE="artifacts/pr-${PR_ID}/all_tests.txt"
          REMAINING_TESTS_FILE="artifacts/pr-${PR_ID}/remaining_tests.txt"

          echo "Finding remaining tests to run..."
          grep -v -F -f $FAILED_TESTS_FILE $ALL_TESTS_FILE > $REMAINING_TESTS_FILE || true

          if [[ -s "$REMAINING_TESTS_FILE" ]]; then
            echo "Remaining tests to run:"
            cat $REMAINING_TESTS_FILE
          else
            echo "No remaining tests to run."
          fi
      
      - name: Set Workflow ID
        shell: bash
        run: echo "WORKFLOW_ID=${{ matrix.name }}" >> $GITHUB_ENV

      - name: Generate Test Commands
        shell: bash
        run: |
          python scripts/generate_pytest_commands.py --input artifacts/pr-${PR_ID}/remaining_tests.txt --output-dir artifacts --pr-id ${PR_ID} --workflow-id ${WORKFLOW_ID} --generate-script --batch-size 20 --tox-env ${{ matrix.tox_env }}

      - name: Display Retrieved Test Results
        shell: bash
        run: |
          RUN_TESTS_FILE="artifacts/pr-${PR_ID}/run_tests.sh"
          if [[ -f "$RUN_TESTS_FILE" ]]; then
            echo "Content of run_tests.sh:"
            cat "$RUN_TESTS_FILE"
          else
            echo "run_tests.sh file does not exist."
          fi

      - name: Run Remaining Test Cases
        shell: bash
        run: |
          REMAINING_TESTS_FILE="artifacts/pr-${PR_ID}/remaining_tests.txt"
          
          if [[ -s "$REMAINING_TESTS_FILE" ]]; then
            echo "Running remaining test cases using tox env ${{ matrix.tox_env }}..."
            
            if [[ -f "artifacts/pr-${PR_ID}/${WORKFLOW_ID}/run_tests.sh" ]]; then
              chmod +x artifacts/pr-${PR_ID}/${WORKFLOW_ID}/run_tests.sh
              bash artifacts/pr-${PR_ID}/${WORKFLOW_ID}/run_tests.sh
              
              # Combine results after running tests
              python scripts/generate_pytest_commands.py --combine-results --output-dir=artifacts --pr-id=${PR_ID} --workflow-id=${WORKFLOW_ID}
            else
              echo "No test script generated."
            fi
          else
            echo "No remaining tests to run."
          fi
              
      - name: Upload New Test Results
        uses: actions/upload-artifact@v4
        with:
          name: pr-${{ env.PR_ID }}-${{ env.WORKFLOW_ID }}-test-results
          path: |
            artifacts/pr-${{ env.PR_ID }}/${{ env.WORKFLOW_ID }}/test_results.json
            artifacts/pr-${{ env.PR_ID }}/${{ env.WORKFLOW_ID }}/*.sh
                
  retrieve-results:
    needs: run-tests
    runs-on: ubuntu-latest
    steps:
      - name: Get PR ID
        if: github.event_name == 'pull_request'
        run: echo "PR_ID=${{ github.event.number }}" >> $GITHUB_ENV

      - name: Set Default Folder for Non-PR Runs
        if: github.event_name != 'pull_request'
        run: echo "PR_ID=main" >> $GITHUB_ENV
      
      - name: Check out code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.9"
      
      - name: Install dependencies
        shell: bash
        run: |
          python -m pip install --upgrade pip
          pip install jq
      
      - name: Create directory for results
        run: mkdir -p retrieved-results

      - name: Download all workflow test results
        uses: actions/download-artifact@v4
        with:
          pattern: pr-${{ env.PR_ID }}-*-test-results
          path: retrieved-results
          merge-multiple: false
      
      - name: Debug directory structure
        shell: bash
        run: |
          echo "Debugging directory structure..."
          find retrieved-results -type f | sort
      
      - name: Extract zip files if needed
        shell: bash
        run: |
          echo "Extracting downloaded artifacts..."
          for zip_file in $(find retrieved-results -name "*.zip"); do
            if [ -f "$zip_file" ]; then
              workflow_dir=$(dirname "$zip_file")
              echo "Extracting $zip_file to $workflow_dir"
              unzip -o "$zip_file" -d "$workflow_dir"
            fi
          done
      
      - name: Find test result files
        shell: bash
        run: |
          echo "======================================="
          echo "Downloaded artifacts for PR ${PR_ID}:"
          find retrieved-results -type f -name "test_results*.json" | sort
          echo "======================================="
      
      - name: Combine test results
        shell: bash
        run: |
          echo "Displaying results per workflow..."
          for result_file in $(find retrieved-results -type f -name "test_results*.json"); do
            echo "---------------------------------------"
            echo "Workflow: $(basename $(dirname "$result_file"))"
            echo "Summary:"
            jq '.summary' "$result_file"
            echo "Failed Tests:"
            jq -r '.tests | map(select(.outcome == "failed")) | .[].nodeid' "$result_file" || echo "No failed tests"
            echo "---------------------------------------"
          done

          echo "Combining test results from all workflows..."
          cat > retrieved-results/combined_results.json << EOF
          {
            "created": "$(date -Iseconds)",
            "duration": 0,
            "exitcode": 0,
            "summary": {
              "passed": 0,
              "failed": 0,
              "skipped": 0,
              "xfailed": 0,
              "xpassed": 0,
              "error": 0,
              "total": 0
            },
            "tests": [],
            "collectors": [],
            "warnings": []
          }
          EOF

          for result_file in $(find retrieved-results -type f -name "test_results*.json"); do
            echo "Processing $result_file"

            if ! jq empty "$result_file" 2>/dev/null; then
              echo "Warning: $result_file is not valid JSON, skipping"
              continue
            fi

            for metric in passed failed skipped xfailed xpassed error total; do
              count=$(jq -r ".summary.$metric // 0" "$result_file")
              current=$(jq -r ".summary.$metric" retrieved-results/combined_results.json)
              new_count=$((current + count))
              jq --arg metric "$metric" --argjson count "$new_count" '.summary[$metric] = $count' retrieved-results/combined_results.json > temp.json && mv temp.json retrieved-results/combined_results.json
            done

            jq -s '.[0].tests = (.[0].tests + (.[1].tests // [])); .[0]' retrieved-results/combined_results.json "$result_file" > temp.json && mv temp.json retrieved-results/combined_results.json

            duration=$(jq -r ".duration // 0" "$result_file")
            current_duration=$(jq -r ".duration" retrieved-results/combined_results.json)
            new_duration=$(echo "$current_duration + $duration" | bc)
            jq --argjson duration "$new_duration" '.duration = $duration' retrieved-results/combined_results.json > temp.json && mv temp.json retrieved-results/combined_results.json

            exitcode=$(jq -r ".exitcode // 0" "$result_file")
            current_exitcode=$(jq -r ".exitcode" retrieved-results/combined_results.json)
            if [ "$exitcode" -ne 0 ] && [ "$current_exitcode" -eq 0 ]; then
              jq --argjson exitcode "$exitcode" '.exitcode = $exitcode' retrieved-results/combined_results.json > temp.json && mv temp.json retrieved-results/combined_results.json
            fi
          done

          cp retrieved-results/combined_results.json retrieved-results/test_results.json

      
      - name: Display Combined Test Results
        shell: bash
        run: |
          echo "======================================="
          echo "Combined Test Results from PR ${PR_ID}:"
          echo "Summary:"
          jq '.summary' retrieved-results/combined_results.json
          echo "Failed Tests:"
          jq -r '.tests | map(select(.outcome == "failed")) | .[].nodeid' retrieved-results/combined_results.json || echo "No failed tests found."
          echo "======================================="
      
      - name: Upload Combined Results
        uses: actions/upload-artifact@v4
        with:
          name: pr-${{ env.PR_ID }}-combined-test-results
          path: retrieved-results/combined_results.json

    

  # # retrieve-results:
  #   needs: run-tests
  #   runs-on: ubuntu-latest
  #   steps:
  #     - name: Get PR ID
  #       if: github.event_name == 'pull_request'
  #       run: echo "PR_ID=${{ github.event.number }}" >> $GITHUB_ENV

  #     - name: Set Default Folder for Non-PR Runs
  #       if: github.event_name != 'pull_request'
  #       run: echo "PR_ID=main" >> $GITHUB_ENV

  #     - name: Download Test Results
  #       uses: actions/download-artifact@v4
  #       with:
  #         name: pr-${{ env.PR_ID }}-test-results
  #         path: retrieved-results

  #     - name: Display Retrieved Test Results
  #       shell: bash
  #       run: |
  #         echo "======================================="
  #         echo "Retrieved Test Results from PR ${PR_ID}:"
  #         cat retrieved-results/test_results.json
  #         echo "======================================="